{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "import gc\n",
    "from sklearn.metrics import r2_score\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.inspection import permutation_importance\n",
    "import os\n",
    "import wandb\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from wandb.integration.lightgbm import wandb_callback, log_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for part_in in [\"6\",\"7\",\"8\",\"9\"]:\n",
    "    part_id = part_in\n",
    "    data_dir = f\"train.parquet/partition_id={part_id}/part-0.parquet\"\n",
    "    df_list.append(pl.read_parquet(data_dir))\n",
    "    gc.collect()\n",
    "\n",
    "responder_cols = [f\"responder_{col}\" for col in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pl.concat(df_list)\n",
    "del df_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daily_stats(train_df, target_col):\n",
    "    daily_avg = (\n",
    "        train_df\n",
    "        .group_by([\"symbol_id\", \"date_id\"], maintain_order = True)\n",
    "        .agg([pl.col(target_col).mean().alias(\"daily_avg\"), \n",
    "            pl.col(target_col).std().alias(\"daily_std\"),\n",
    "            pl.col(target_col).min().alias(\"daily_min\"),\n",
    "            pl.col(target_col).max().alias(\"daily_max\"),\n",
    "            pl.col(target_col).median().alias(\"daily_median\"),\n",
    "            pl.col(target_col).skew().alias(\"daily_skew\"),\n",
    "            pl.col(target_col).kurtosis().alias(\"daily_kurtosis\"),\n",
    "            pl.col(target_col).last().alias(\"last_value\"),\n",
    "            pl.col(target_col).first().alias(\"first_value\"),\n",
    "            (pl.col(target_col).max() - pl.col(target_col).min()).alias(\"daily_range\"),\n",
    "            pl.col(target_col).sum().alias(\"target_sum\"),\n",
    "            pl.col(target_col).count().alias(\"daily_count\")\n",
    "            ]\n",
    "            )\n",
    "    )\n",
    "    daily_avg = daily_avg.sort([\"symbol_id\", \"date_id\"])\n",
    "\n",
    "    columns_to_shift = [\"daily_avg\", \"daily_std\", \"daily_min\", \"daily_max\", \"daily_median\", \"daily_skew\", \"daily_kurtosis\", \"last_value\", \"first_value\",\n",
    "    \"daily_range\", \"target_sum\", \"date_id\", \"daily_count\"]\n",
    "\n",
    "    daily_avg = daily_avg.with_columns([\n",
    "        pl.col(col_name)\n",
    "        .shift(1)\n",
    "        .over(\"symbol_id\")\n",
    "        .alias(f\"lag_1_{col_name}_{target_col}\")\n",
    "        for col_name in columns_to_shift\n",
    "    ])\n",
    "\n",
    "    daily_avg = daily_avg.with_columns(\n",
    "    (pl.col(\"date_id\") - pl.col(\"lag_1_date_id_responder_6\"))\n",
    "    .alias(\"days_since_lag_1\")\n",
    "    )\n",
    "\n",
    "    s1 = [f\"lag_1_{col_name}_{target_col}\" for col_name in columns_to_shift if col_name != \"date_id\"]\n",
    "\n",
    "    selected_cols = [\"symbol_id\",\"date_id\", \"days_since_lag_1\"] + s1\n",
    "    daily_avg = daily_avg.select(selected_cols)\n",
    "\n",
    "    train_df = train_df.join(daily_avg,\n",
    "              on=[\"symbol_id\", \"date_id\"],\n",
    "              how=\"left\")\n",
    "\n",
    "    return train_df\n",
    "\n",
    "def create_daily_stats2(train_df, target_col):\n",
    "    daily_avg = (\n",
    "        train_df\n",
    "        .group_by([\"symbol_id\", \"date_id\"], maintain_order = True)\n",
    "        .agg([pl.col(target_col).mean().alias(\"daily_avg\"), \n",
    "            pl.col(target_col).std().alias(\"daily_std\"),\n",
    "            pl.col(target_col).min().alias(\"daily_min\"),\n",
    "            pl.col(target_col).max().alias(\"daily_max\"),\n",
    "            pl.col(target_col).median().alias(\"daily_median\"),\n",
    "            pl.col(target_col).last().alias(\"last_value\"),\n",
    "            (pl.col(target_col).max() - pl.col(target_col).min()).alias(\"daily_range\"),\n",
    "            pl.col(target_col).sum().alias(\"target_sum\"),\n",
    "            ]\n",
    "            )\n",
    "    )\n",
    "    daily_avg = daily_avg.sort([\"symbol_id\", \"date_id\"])\n",
    "\n",
    "    columns_to_shift = [\"daily_avg\", \"daily_std\", \"daily_min\", \"daily_max\", \"daily_median\", \"last_value\",\"daily_range\", \"target_sum\"]\n",
    "\n",
    "    daily_avg = daily_avg.with_columns([\n",
    "        pl.col(col_name)\n",
    "        .shift(1)\n",
    "        .over(\"symbol_id\")\n",
    "        .alias(f\"lag_1_{col_name}_{target_col}\")\n",
    "        for col_name in columns_to_shift\n",
    "    ])\n",
    "\n",
    "\n",
    "    s1 = [f\"lag_1_{col_name}_{target_col}\" for col_name in columns_to_shift if col_name != \"date_id\"]\n",
    "\n",
    "    selected_cols = [\"symbol_id\",\"date_id\"] + s1\n",
    "    daily_avg = daily_avg.select(selected_cols)\n",
    "\n",
    "    train_df = train_df.join(daily_avg,\n",
    "              on=[\"symbol_id\", \"date_id\"],\n",
    "              how=\"left\")\n",
    "\n",
    "    train_df = train_df.sort([\"date_id\", \"time_id\", \"symbol_id\"])\n",
    "    gc.collect()\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 2min 11s, total: 4min 33s\n",
      "Wall time: 27.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for col_name in [\"responder_6\"]:\n",
    "    train_df = create_daily_stats(train_df, col_name)\n",
    "gc.collect()\n",
    "\n",
    "for col_name in [\"responder_0\",\"responder_1\",\"responder_2\",\"responder_3\",\"responder_4\",\"responder_5\",\"responder_7\",\"responder_8\"]:\n",
    "    train_df = create_daily_stats2(train_df, col_name)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.with_columns([\n",
    "    (2 * np.pi * pl.col(\"time_id\") / 967).sin().alias(\"sin_time_id\").cast(pl.Float32),\n",
    "    (2 * np.pi * pl.col(\"time_id\") / 967).cos().alias(\"cos_time_id\").cast(pl.Float32),\n",
    "    (2 * np.pi * pl.col(\"time_id\") / 483).sin().alias(\"sin_time_id_halfday\").cast(pl.Float32),\n",
    "    (2 * np.pi * pl.col(\"time_id\") / 483).cos().alias(\"cos_time_id_halfday\").cast(pl.Float32),\n",
    "])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 s, sys: 4.47 s, total: 6.46 s\n",
      "Wall time: 543 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "default_features = [f\"feature_{idx:02d}\" for idx in range(79)]\n",
    "train_df = train_df.with_columns(null_count = pl.sum_horizontal([pl.col(col).is_null() for col in default_features]))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polars_train_df = train_df\n",
    "train_df = polars_train_df.to_pandas()\n",
    "del polars_train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"symbol_id\"] = train_df[\"symbol_id\"].astype(\"category\")\n",
    "train_df[\"feature_10\"] = train_df[\"feature_10\"].astype(\"category\")\n",
    "train_df[\"feature_11\"] = train_df[\"feature_11\"].astype(\"category\")\n",
    "train_df[\"feature_09\"] = train_df[\"feature_09\"].astype(\"category\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df[train_df[\"date_id\"] < 1550].copy()\n",
    "X_test = train_df[train_df[\"date_id\"] >= 1550].copy()\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = X_train[\"responder_6\"].copy()\n",
    "y_test = X_test[\"responder_6\"].copy()\n",
    "test_weights = X_test[\"weight\"].values.copy()\n",
    "train_weights = X_train[\"weight\"].values.copy()\n",
    "X_train.drop(columns = responder_cols, axis=1, inplace = True)\n",
    "X_test.drop(columns = responder_cols, axis=1, inplace = True)\n",
    "X_train.drop(columns = [\"weight\"], axis = 1, inplace = True)\n",
    "X_test.drop(columns = [\"weight\"], axis = 1, inplace = True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = joblib.load(\"model_cols/lgb_v7_model_cols.pkl\")\n",
    "feature_cols = feature_cols \n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    \"objective\": \"rmse\",\n",
    "    \"random_state\": 16,\n",
    "    \"max_cat_to_onehot\": 64,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": 10,\n",
    "    \"verbosity\": -1,\n",
    "    \"metric\": \"rmse\",\n",
    "    \"n_estimators\" : 500,\n",
    "    \"n_jobs\" : 16,\n",
    "    \"force_row_wise\" : True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain's rmse: 0.815762\ttrain's weighted_r2: 0.00650369\ttest's rmse: 0.800965\ttest's weighted_r2: 0.00261528\n",
      "[100]\ttrain's rmse: 0.814169\ttrain's weighted_r2: 0.0103792\ttest's rmse: 0.800419\ttest's weighted_r2: 0.0039735\n",
      "[150]\ttrain's rmse: 0.812929\ttrain's weighted_r2: 0.0133919\ttest's rmse: 0.80007\ttest's weighted_r2: 0.00484244\n",
      "[200]\ttrain's rmse: 0.811805\ttrain's weighted_r2: 0.0161187\ttest's rmse: 0.799856\ttest's weighted_r2: 0.00537484\n",
      "[250]\ttrain's rmse: 0.810677\ttrain's weighted_r2: 0.0188507\ttest's rmse: 0.799677\ttest's weighted_r2: 0.00581905\n",
      "[300]\ttrain's rmse: 0.809553\ttrain's weighted_r2: 0.021568\ttest's rmse: 0.799566\ttest's weighted_r2: 0.00609543\n",
      "[350]\ttrain's rmse: 0.808543\ttrain's weighted_r2: 0.024008\ttest's rmse: 0.799462\ttest's weighted_r2: 0.0063535\n",
      "[400]\ttrain's rmse: 0.80771\ttrain's weighted_r2: 0.0260193\ttest's rmse: 0.799399\ttest's weighted_r2: 0.00651183\n",
      "[450]\ttrain's rmse: 0.806876\ttrain's weighted_r2: 0.0280289\ttest's rmse: 0.79936\ttest's weighted_r2: 0.00660905\n",
      "[500]\ttrain's rmse: 0.805983\ttrain's weighted_r2: 0.0301799\ttest's rmse: 0.799332\ttest's weighted_r2: 0.00667852\n",
      "R2 Score: 0.00668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weighted_r2_metric(y_true, y_pred, weights=None):\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(y_true)\n",
    "\n",
    "    numerator = np.sum(weights * (y_true - y_pred)**2)\n",
    "    y_weighted_mean = np.sum(weights * y_true) / np.sum(weights)\n",
    "    denominator = np.sum(weights * (y_true - y_weighted_mean)**2)\n",
    "\n",
    "    score = 1 - (numerator / denominator)\n",
    "    return 'weighted_r2', score, True\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(objective = \"rmse\",\n",
    "                                 random_state = 16,\n",
    "                                 max_cat_to_onehot = 64,\n",
    "                                 n_estimators = 500,\n",
    "                                 learning_rate = 0.01,\n",
    "                                 verbosity = -1,\n",
    "                                 max_depth = 10,\n",
    "                                 force_row_wise = True,\n",
    "                                 histogram_pool_size = 30_000)\n",
    "\n",
    "lgb_model.fit(X_train, y_train, \n",
    "                eval_set = [(X_test, y_test), (X_train, y_train)],\n",
    "                eval_metric = weighted_r2_metric,\n",
    "                eval_names = [\"test\", \"train\"],\n",
    "                callbacks=[lgb.log_evaluation(50)], \n",
    "                sample_weight = train_weights,\n",
    "                eval_sample_weight = [test_weights])\n",
    "\n",
    "y_pred_lgb = np.clip(lgb_model.predict(X_test), -5, 5)\n",
    "\n",
    "r_score_lgb = r2_score(y_test, y_pred_lgb, sample_weight = test_weights)\n",
    "print(f\"R2 Score: {r_score_lgb:.5f}\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mturkenm\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mt/Desktop/JaneStreet-Comp/wandb/run-20250113_182857-pke6joat</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/turkenm/js_lgbm/runs/pke6joat' target=\"_blank\">lgb_run_82135</a></strong> to <a href='https://wandb.ai/turkenm/js_lgbm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/turkenm/js_lgbm' target=\"_blank\">https://wandb.ai/turkenm/js_lgbm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/turkenm/js_lgbm/runs/pke6joat' target=\"_blank\">https://wandb.ai/turkenm/js_lgbm/runs/pke6joat</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mt/miniconda3/envs/tabm/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain's rmse: 0.827328\ttrain's weighted_r2: 0.00552862\ttest's rmse: 0.800932\ttest's weighted_r2: 0.0027052\n",
      "[100]\ttrain's rmse: 0.825996\ttrain's weighted_r2: 0.00872725\ttest's rmse: 0.800409\ttest's weighted_r2: 0.00400766\n",
      "[150]\ttrain's rmse: 0.825052\ttrain's weighted_r2: 0.0109913\ttest's rmse: 0.80006\ttest's weighted_r2: 0.00487487\n",
      "[200]\ttrain's rmse: 0.82424\ttrain's weighted_r2: 0.012938\ttest's rmse: 0.799796\ttest's weighted_r2: 0.00553064\n",
      "[250]\ttrain's rmse: 0.823543\ttrain's weighted_r2: 0.0146055\ttest's rmse: 0.799608\ttest's weighted_r2: 0.00599804\n",
      "[300]\ttrain's rmse: 0.822894\ttrain's weighted_r2: 0.0161597\ttest's rmse: 0.799449\ttest's weighted_r2: 0.00639347\n",
      "[350]\ttrain's rmse: 0.822288\ttrain's weighted_r2: 0.0176072\ttest's rmse: 0.799318\ttest's weighted_r2: 0.00671971\n",
      "[400]\ttrain's rmse: 0.82165\ttrain's weighted_r2: 0.0191315\ttest's rmse: 0.799211\ttest's weighted_r2: 0.00698654\n",
      "[450]\ttrain's rmse: 0.821056\ttrain's weighted_r2: 0.0205482\ttest's rmse: 0.799122\ttest's weighted_r2: 0.00720664\n",
      "[500]\ttrain's rmse: 0.820532\ttrain's weighted_r2: 0.0217994\ttest's rmse: 0.799047\ttest's weighted_r2: 0.00739209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d7f21e6559456b9b64a1bdcf84e152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.776 MB of 1.776 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_rmse</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_weighted_r2</td><td>▁▂▂▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_rmse</td><td>█▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_weighted_r2</td><td>▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>0</td></tr><tr><td>best_test_r2</td><td>0.00739</td></tr><tr><td>best_train_r2</td><td>0.0218</td></tr><tr><td>iteration</td><td>499</td></tr><tr><td>test_weighted_r2</td><td>0.00739</td></tr><tr><td>train_weighted_r2</td><td>0.0218</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lgb_run_82135</strong> at: <a href='https://wandb.ai/turkenm/js_lgbm/runs/pke6joat' target=\"_blank\">https://wandb.ai/turkenm/js_lgbm/runs/pke6joat</a><br/> View project at: <a href='https://wandb.ai/turkenm/js_lgbm' target=\"_blank\">https://wandb.ai/turkenm/js_lgbm</a><br/>Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_182857-pke6joat/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "short_id = int(time.time()) % 100_000\n",
    "\n",
    "run_name = f\"lgb_run_{short_id}\"\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"rmse\",\n",
    "    \"random_state\": 16,\n",
    "    \"max_cat_to_onehot\": 64,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": 10,\n",
    "    \"verbosity\": -1,\n",
    "    \"metric\": \"rmse\",\n",
    "    \"n_estimators\" : 500,\n",
    "    \"n_jobs\" : 16,\n",
    "    \"force_row_wise\" : True,\n",
    "}\n",
    "\n",
    "wandb.init(project='js_lgbm', \n",
    "        name = run_name,\n",
    "        tags = [\"exp\", \"lgb_v8\"], \n",
    "        config=lgb_params)\n",
    "\n",
    "def weighted_r2_metric(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    weight = dataset.get_weight()\n",
    "    ss_res = ((weight * (y_true - y_pred) ** 2).sum())\n",
    "    ss_tot = ((weight * (y_true - y_true.mean()) ** 2).sum())\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return \"weighted_r2\", r2, True  \n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    data=X_train[feature_cols],\n",
    "    label=y_train, \n",
    "    weight=train_weights, \n",
    "    categorical_feature=[\"symbol_id\",\"feature_09\",\"feature_10\", \"feature_11\"],\n",
    ")\n",
    "test_data = lgb.Dataset(\n",
    "    data=X_test[feature_cols], \n",
    "    label=y_test, \n",
    "    weight=test_weights, \n",
    "    categorical_feature=[\"symbol_id\",\"feature_09\",\"feature_10\",\"feature_11\"],\n",
    "    reference = train_data)\n",
    "\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    params=lgb_params,\n",
    "    train_set=train_data,\n",
    "    valid_sets=[train_data,test_data], \n",
    "    valid_names=[\"train\",\"test\"],\n",
    "    feval=weighted_r2_metric,  \n",
    "    callbacks=[lgb.log_evaluation(50),\n",
    "                wandb_callback()] \n",
    "    )\n",
    "\n",
    "best_test_r2 = lgb_model.best_score[\"test\"][\"weighted_r2\"]\n",
    "best_train_r2 = lgb_model.best_score[\"train\"][\"weighted_r2\"]\n",
    "\n",
    "wandb.run.summary[\"best_test_r2\"] = best_test_r2\n",
    "wandb.run.summary[\"best_train_r2\"] = best_train_r2\n",
    "\n",
    "log_summary(lgb_model, save_model_checkpoint=True)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x75fd08199f30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.save_model(\"lgb_model_results/lgb_v8_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train[\"responder_6\"].copy()\n",
    "y_test = X_test[\"responder_6\"].copy()\n",
    "test_weights = X_test[\"weight\"].values.copy()\n",
    "train_weights = X_train[\"weight\"].values.copy()\n",
    "X_train.drop(columns = responder_cols, axis=1, inplace = True)\n",
    "X_test.drop(columns = responder_cols, axis=1, inplace = True)\n",
    "X_train.drop(columns = [\"weight\"], axis = 1, inplace = True)\n",
    "X_test.drop(columns = [\"weight\"], axis = 1, inplace = True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df[\"responder_6\"].copy()\n",
    "train_weights = train_df[\"weight\"].values.copy()\n",
    "train_df.drop(columns=[col for col in train_df.columns if col not in feature_cols], inplace=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.19.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mt/Desktop/JaneStreet-Comp/wandb/run-20250113_174254-rki4st6x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/turkenm/js_lgbm/runs/rki4st6x' target=\"_blank\">lgb_run_79373</a></strong> to <a href='https://wandb.ai/turkenm/js_lgbm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/turkenm/js_lgbm' target=\"_blank\">https://wandb.ai/turkenm/js_lgbm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/turkenm/js_lgbm/runs/rki4st6x' target=\"_blank\">https://wandb.ai/turkenm/js_lgbm/runs/rki4st6x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mt/miniconda3/envs/tabm/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain's rmse: 0.821027\ttrain's weighted_r2: 0.00478899\n",
      "[100]\ttrain's rmse: 0.819917\ttrain's weighted_r2: 0.00747854\n",
      "[150]\ttrain's rmse: 0.819107\ttrain's weighted_r2: 0.00943679\n",
      "[200]\ttrain's rmse: 0.818458\ttrain's weighted_r2: 0.0110077\n",
      "[250]\ttrain's rmse: 0.817844\ttrain's weighted_r2: 0.012489\n",
      "[300]\ttrain's rmse: 0.817194\ttrain's weighted_r2: 0.0140602\n",
      "[350]\ttrain's rmse: 0.816559\ttrain's weighted_r2: 0.0155919\n",
      "[400]\ttrain's rmse: 0.815984\ttrain's weighted_r2: 0.0169773\n",
      "[450]\ttrain's rmse: 0.815454\ttrain's weighted_r2: 0.0182533\n",
      "[500]\ttrain's rmse: 0.814917\ttrain's weighted_r2: 0.0195451\n",
      "[550]\ttrain's rmse: 0.814402\ttrain's weighted_r2: 0.0207844\n",
      "[600]\ttrain's rmse: 0.813905\ttrain's weighted_r2: 0.0219783\n",
      "[650]\ttrain's rmse: 0.813462\ttrain's weighted_r2: 0.0230433\n",
      "[700]\ttrain's rmse: 0.813097\ttrain's weighted_r2: 0.0239197\n",
      "[750]\ttrain's rmse: 0.812644\ttrain's weighted_r2: 0.0250087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e81b83989348d9a95791f9d44e03ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_rmse</td><td>██▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_weighted_r2</td><td>▁▁▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>0</td></tr><tr><td>best_train_r2</td><td>0.02501</td></tr><tr><td>iteration</td><td>749</td></tr><tr><td>train_weighted_r2</td><td>0.02501</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lgb_run_79373</strong> at: <a href='https://wandb.ai/turkenm/js_lgbm/runs/rki4st6x' target=\"_blank\">https://wandb.ai/turkenm/js_lgbm/runs/rki4st6x</a><br/> View project at: <a href='https://wandb.ai/turkenm/js_lgbm' target=\"_blank\">https://wandb.ai/turkenm/js_lgbm</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_174254-rki4st6x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "short_id = int(time.time()) % 100_000\n",
    "\n",
    "run_name = f\"lgb_run_{short_id}\"\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"rmse\",\n",
    "    \"random_state\": 16,\n",
    "    \"max_cat_to_onehot\": 64,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": 10,\n",
    "    \"verbosity\": -1,\n",
    "    \"metric\": \"rmse\",\n",
    "    \"n_estimators\" : 750,\n",
    "    \"n_jobs\" : 16,\n",
    "    \"force_row_wise\" : True,\n",
    "}\n",
    "\n",
    "inference_data = lgb.Dataset(\n",
    "    data=train_df[feature_cols],\n",
    "    label=y_train, \n",
    "    weight=train_weights, \n",
    "    categorical_feature=[\"symbol_id\",\"feature_09\",\"feature_10\", \"feature_11\"],\n",
    ")\n",
    "\n",
    "wandb.init(project='js_lgbm', \n",
    "        name = run_name,\n",
    "        tags = [\"inference\", \"lgb_v8\"], \n",
    "        config=lgb_params)\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    params=lgb_params,\n",
    "    train_set=inference_data,\n",
    "    valid_sets=[inference_data], \n",
    "    valid_names=[\"train\"],\n",
    "    feval=weighted_r2_metric,  \n",
    "    callbacks=[lgb.log_evaluation(50),\n",
    "                wandb_callback()] \n",
    "    )\n",
    "\n",
    "best_train_r2 = lgb_model.best_score[\"train\"][\"weighted_r2\"]\n",
    "wandb.run.summary[\"best_train_r2\"] = best_train_r2\n",
    "log_summary(lgb_model)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_cols/lgb_v8_model_cols.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.save_model(\"lgb_model_results/lgb_v8.txt\")\n",
    "joblib.dump(feature_cols, \"model_cols/lgb_v8_model_cols.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
